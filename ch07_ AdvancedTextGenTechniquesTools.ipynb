{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashishkhurana01/Hands-On-LLM/blob/main/ch07_%20AdvancedTextGenTechniquesTools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUcXxb07nrYZ"
      },
      "source": [
        "# Advanced Text Gen Tools"
      ],
      "id": "hUcXxb07nrYZ"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FmPTq29UnrYa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain>=0.1.17 openai>=1.13.3 langchain_openai>=0.1.6 transformers>=4.40.1 datasets>=2.18.0 accelerate>=0.27.2 sentence-transformers>=2.5.1 duckduckgo-search>=5.2.2 langchain_community\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python==0.2.69"
      ],
      "id": "FmPTq29UnrYa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an LLM\n",
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk5C16cXqwC9",
        "outputId": "e0072248-7b96-4dd2-e40a-4fdc2bc26904"
      },
      "id": "kk5C16cXqwC9",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-27 02:51:00--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.118, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1737949860&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzk0OTg2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=EczKDJXHXKfZAqZYdZTElr52tufcQdDoGwRQON1Xfa7ch3PV1okzredVdoncM1BUm5QtKAj-lJxM3U1yY8jDREfQKJeaM1lntdAsSjnIYlri-A5eyppIuhGpx2mn%7EG-NSRwvl7b2yjFGjZm%7E0I6eyF4a22eLQ3D5XUeSQFGbo4-Eo1hMhtKk2SJZ4Omi9bowKPOdW%7E8dEy4s5Kp8B1G-ecaMUMwMLgMV5LGRJ66V%7EjtXQ2H4jif6qS%7EvTX8F1zyMjDAymeJS0d%7ELnnHLHQFfG5tsDM--u4FIVBVlrV5qpEf3v1DG3CcWof1itQS-w3VgZFx0zUd3MVWsSTM2Eu8wyw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-01-27 02:51:00--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1737949860&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzk0OTg2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=EczKDJXHXKfZAqZYdZTElr52tufcQdDoGwRQON1Xfa7ch3PV1okzredVdoncM1BUm5QtKAj-lJxM3U1yY8jDREfQKJeaM1lntdAsSjnIYlri-A5eyppIuhGpx2mn%7EG-NSRwvl7b2yjFGjZm%7E0I6eyF4a22eLQ3D5XUeSQFGbo4-Eo1hMhtKk2SJZ4Omi9bowKPOdW%7E8dEy4s5Kp8B1G-ecaMUMwMLgMV5LGRJ66V%7EjtXQ2H4jif6qS%7EvTX8F1zyMjDAymeJS0d%7ELnnHLHQFfG5tsDM--u4FIVBVlrV5qpEf3v1DG3CcWof1itQS-w3VgZFx0zUd3MVWsSTM2Eu8wyw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.164.174.19, 18.164.174.52, 18.164.174.98, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.164.174.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7643295904 (7.1G) [binary/octet-stream]\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-fp16.gguf’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   7.12G  40.0MB/s    in 3m 1s   \n",
            "\n",
            "2025-01-27 02:54:02 (40.2 MB/s) - ‘Phi-3-mini-4k-instruct-fp16.gguf’ saved [7643295904/7643295904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LlamaCpp\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "j7eSx2PprR64"
      },
      "id": "j7eSx2PprR64",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hi! My name is Maarten. What is 1 + 1?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8ZQWC7YgrlaO",
        "outputId": "b4f332c7-074d-4045-e8af-550b624307aa"
      },
      "id": "8ZQWC7YgrlaO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chains**"
      ],
      "metadata": {
        "id": "u93mb3HTr0H4"
      },
      "id": "u93mb3HTr0H4"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# Create a prompt template with the \"input_prompt\" variable\n",
        "template = \"\"\"<s><|user|>\n",
        "{input_prompt}<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input_prompt\"]\n",
        ")"
      ],
      "metadata": {
        "id": "aOY5IAPQr4LA"
      },
      "id": "aOY5IAPQr4LA",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain = prompt | llm"
      ],
      "metadata": {
        "id": "8DgMHUC8ug4C"
      },
      "id": "8DgMHUC8ug4C",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the chain\n",
        "basic_chain.invoke(\n",
        "    {\n",
        "        \"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "8h8x7WE4umwi",
        "outputId": "6ed1260e-2ecc-48e0-9dec-0447a24ea4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "8h8x7WE4umwi",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello Maarten, the answer to 1 + 1 is 2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Chains**"
      ],
      "metadata": {
        "id": "H4-Pc0-Xvc1G"
      },
      "id": "H4-Pc0-Xvc1G"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create a chain for the title of our story\n",
        "template = \"\"\"<s><|user|>\n",
        "Create a title for a story about {summary}. Only return the title.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "title_prompt = PromptTemplate(template=template, input_variables=[\"summary\"])\n",
        "title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
      ],
      "metadata": {
        "id": "oeUyJaF6vf0A",
        "outputId": "116a9ad5-5b9d-4104-db2e-8ec555009769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oeUyJaF6vf0A",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-61dd782c6da9>:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title.invoke({\"summary\": \"a girl that lost her way\"})"
      ],
      "metadata": {
        "id": "uPLLKfqH2BtJ",
        "outputId": "299dc1ef-cf11-425a-e325-a68c4217637c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uPLLKfqH2BtJ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'a girl that lost her way',\n",
              " 'title': ' \"Lost Paths: A Journey of Self-Discovery\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chain for the character description using the summary and title\n",
        "template = \"\"\"<s><|user|>\n",
        "Describe the main character of a story about {summary} with the title {title}. Use only two sentences.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "character_prompt = PromptTemplate(\n",
        "    template=template, input_variables=[\"summary\", \"title\"]\n",
        ")\n",
        "character = LLMChain(llm=llm, prompt=character_prompt, output_key=\"character\")"
      ],
      "metadata": {
        "id": "ht-S-NXw2IQt"
      },
      "id": "ht-S-NXw2IQt",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chain for the story using the summary, title, and character description\n",
        "template = \"\"\"<s><|user|>\n",
        "Create a story about {summary} with the title {title}. The main charachter is: {character}. Only return the story and it cannot be longer than one paragraph<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "story_prompt = PromptTemplate(\n",
        "    template=template, input_variables=[\"summary\", \"title\", \"character\"]\n",
        ")\n",
        "story = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
      ],
      "metadata": {
        "id": "qKTKjZ582aFI"
      },
      "id": "qKTKjZ582aFI",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all three components to create the full chain\n",
        "llm_chain = title | character | story"
      ],
      "metadata": {
        "id": "6g1Rz2PO2fD-"
      },
      "id": "6g1Rz2PO2fD-",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke(\"a girl that lost her way\")"
      ],
      "metadata": {
        "id": "orfSXlsE2iJV",
        "outputId": "e356ac2c-4bff-42ce-85e3-54c7f3e29e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "orfSXlsE2iJV",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'a girl that lost her way',\n",
              " 'title': ' \"Trapped in Transition: The Journey of Lily, Lost and Found\"',\n",
              " 'character': \" Lily is an intelligent and resilient young woman who faces adversity head-on as she navigates through life's challenges following a traumatic event that leaves her feeling lost and disconnected from the world around her. With courage in her heart, she embarks on a journey of self-discovery to find her purpose and reconnect with those she loves while learning valuable lessons about love, friendship, and resilience along the way.\",\n",
              " 'story': ' \"Trapped in Transition: The Journey of Lily, Lost and Found\" is a poignant tale that follows Lily, an intelligent and resilient young woman who finds herself navigating life\\'s tumultuous challenges after enduring a traumatic event. Feeling lost and disconnected from the world around her, she embarks on a courageous journey of self-discovery to find purpose and reconnect with loved ones while learning invaluable lessons about love, friendship, and resilience along the way. Through each twist and turn, Lily\\'s tenacity shines through as she overcomes obstacles, confronts her fears, and ultimately emerges stronger than ever before, finding solace and belonging within herself while forging lasting connections with those who stand by her side.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}